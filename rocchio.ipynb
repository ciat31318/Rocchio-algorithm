{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query_list = []\n",
    "doc_list = []\n",
    "\n",
    "with open('./query_list.txt',\"r\") as querys:\n",
    "    for query in querys:\n",
    "        query_list.append(query.strip())\n",
    "with open('./doc_list.txt',\"r\") as docs:\n",
    "    for doc in docs:\n",
    "        doc_list.append(doc.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                        \n",
    "query_word = []                                #製造要變成 tfidf 的原始資料矩陣\n",
    "for query in query_list:\n",
    "    with open('./Query/'+query,\"r\") as f:\n",
    "        a=' '\n",
    "        for line in f:\n",
    "            s=line.strip()[:-2]\n",
    "            a+=s\n",
    "        query_word.append(a)\n",
    "\n",
    "doc_word = []\n",
    "for doc in doc_list:\n",
    "    with open('./Document/'+doc,\"r\") as f:\n",
    "        a = ' '\n",
    "        f = f.readlines()[3:]\n",
    "        lines = [line.strip()[:-2] for line in f]\n",
    "        b = ''.join(lines)\n",
    "        doc_word.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2265, 13290)\n",
      "(800, 13290)\n",
      "Wall time: 581 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_model = TfidfVectorizer(token_pattern='[0-9]+')                #用套件變成tfidf矩陣\n",
    "doc_vector = tfidf_model.fit_transform(doc_word)\n",
    "q_vector = tfidf_model.transform(query_word)\n",
    "q_vector = q_vector.toarray()\n",
    "q_len , word_len = q_vector.shape\n",
    "\n",
    "print(doc_vector.shape)\n",
    "print(q_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 321 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rank = cosine_similarity(q_vector,doc_vector)    #算cosine 值\n",
    "def roc(q_vector,rank,doc_vector):               #做出訓練的演算法函數\n",
    "    for i in range(q_len):\n",
    "        a = np.argsort(rank[i])\n",
    "        a1 = a[:5]\n",
    "        a2 = list(reversed(a))[:5]\n",
    "        sum1 = []\n",
    "        sum2 = []\n",
    "        for j in a1:\n",
    "            if sum1==[]:\n",
    "                sum1=doc_vector[j]\n",
    "            else:\n",
    "                sum1+=doc_vector[j]\n",
    "        for k in a2:\n",
    "            if sum2==[]:\n",
    "                sum2=doc_vector[k]\n",
    "            else:\n",
    "                sum2+=doc_vector[k]\n",
    "        q_vector[i] = alpha*q_vector[i]+beta*(1/len(a2))*sum2-gama*(1/len(a1))*sum1\n",
    "    rank = cosine_similarity(q_vector,doc_vector)\n",
    "    return q_vector ,rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 2265)\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "alpha=0.7\n",
    "beta=0.4\n",
    "gama=0.3\n",
    "for i in range(5):                  #演算法函數跑五次\n",
    "    q_vector,rank=roc(q_vector,rank,doc_vector)\n",
    "new_rank = cosine_similarity(q_vector,doc_vector)\n",
    "print(new_rank.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"submission.txt\",\"w\")                 #選出50筆由大到小寫入\n",
    "f.write(\"Query,RetrievedDocuments\\n\")\n",
    "i=0\n",
    "for query in query_list:\n",
    "    f.write(query+\",\")\n",
    "    b=np.argsort(new_rank[i])\n",
    "    b1=list(reversed(b))[:50]\n",
    "    for t in b1:\n",
    "        f.write(doc_list[t]+\" \")\n",
    "    f.write(\"\\n\")\n",
    "    i+=1\n",
    "f.close()                                #到此結束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
